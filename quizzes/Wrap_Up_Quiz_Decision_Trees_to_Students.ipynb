{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ithabi/AAA/blob/main/quizzes/Wrap_Up_Quiz_Decision_Trees_to_Students.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 1 : c)\n",
        "\n",
        "QUESTION 2 : a)\n",
        "\n",
        "QUESTION 3 :\n",
        "\n",
        "QUESTION 4 :"
      ],
      "metadata": {
        "id": "rgFOPNRRAQeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "ames_housing = pd.read_csv(\"https://raw.githubusercontent.com/bilals/scikit-learn-mooc/main/datasets/ames_housing_no_missing.csv\")\n",
        "target_name = \"SalePrice\"\n",
        "data = ames_housing.drop(columns=target_name)\n",
        "target = ames_housing[target_name]\n",
        "numerical_features = [\n",
        "    \"LotFrontage\", \"LotArea\", \"MasVnrArea\", \"BsmtFinSF1\", \"BsmtFinSF2\",\n",
        "    \"BsmtUnfSF\", \"TotalBsmtSF\", \"1stFlrSF\", \"2ndFlrSF\", \"LowQualFinSF\",\n",
        "    \"GrLivArea\", \"BedroomAbvGr\", \"KitchenAbvGr\", \"TotRmsAbvGrd\", \"Fireplaces\",\n",
        "    \"GarageCars\", \"GarageArea\", \"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\",\n",
        "    \"3SsnPorch\", \"ScreenPorch\", \"PoolArea\", \"MiscVal\",\n",
        "]\n",
        "\n",
        "data_numerical = data[numerical_features]\n"
      ],
      "metadata": {
        "id": "aIx6PF-lAHFo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wrap-up quiz - Decision Trees\n",
        "\n",
        "**This quiz requires some programming to be answered.**\n",
        "\n",
        "Open the dataset `ames_housing_no_missing.csv` with the following command:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "ames_housing = pd.read_csv(\"https://raw.githubusercontent.com/bilals/scikit-learn-mooc/main/datasets/ames_housing_no_missing.csv\")\n",
        "target_name = \"SalePrice\"\n",
        "data = ames_housing.drop(columns=target_name)\n",
        "target = ames_housing[target_name]\n",
        "```\n",
        "\n",
        "`ames_housing` is a pandas dataframe. The column \"SalePrice\" contains the\n",
        "target variable.\n",
        "\n",
        "To simplify this exercise, we will only used the numerical features defined\n",
        "below:\n",
        "\n",
        "```python\n",
        "numerical_features = [\n",
        "    \"LotFrontage\", \"LotArea\", \"MasVnrArea\", \"BsmtFinSF1\", \"BsmtFinSF2\",\n",
        "    \"BsmtUnfSF\", \"TotalBsmtSF\", \"1stFlrSF\", \"2ndFlrSF\", \"LowQualFinSF\",\n",
        "    \"GrLivArea\", \"BedroomAbvGr\", \"KitchenAbvGr\", \"TotRmsAbvGrd\", \"Fireplaces\",\n",
        "    \"GarageCars\", \"GarageArea\", \"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\",\n",
        "    \"3SsnPorch\", \"ScreenPorch\", \"PoolArea\", \"MiscVal\",\n",
        "]\n",
        "\n",
        "data_numerical = data[numerical_features]\n",
        "```\n",
        "\n",
        "We will compare the generalization performance of a decision tree and a linear\n",
        "regression. For this purpose, we will create two separate predictive models\n",
        "and evaluate them by 10-fold cross-validation.\n",
        "\n",
        "Thus, use `sklearn.linear_model.LinearRegression` and\n",
        "`sklearn.tree.DecisionTreeRegressor` to create the models. Use the default\n",
        "parameters for the linear regression and set `random_state=0` for the decision\n",
        "tree.\n",
        "\n",
        "Be aware that a linear model requires to scale numerical features.\n",
        "Please use `sklearn.preprocessing.StandardScaler` so that your\n",
        "linear regression model behaves the same way as the quiz author\n",
        "intended ;)\n",
        "\n",
        "## Question 1\n",
        "```\n",
        "By comparing the cross-validation test scores for both models fold-to-fold, count the number of\n",
        "times the linear model has a better test score than the decision tree model.\n",
        "Select the range which this number belongs to:\n",
        "\n",
        "- a) [0, 3]: the linear model is substantially worse than the decision tree\n",
        "- b) [4, 6]: both models are almost equivalent\n",
        "- c) [7, 10]: the linear model is substantially better than the decision tree\n",
        "\n",
        "_Select a single answer_\n",
        "```\n",
        "\n",
        "\n",
        "Instead of using the default parameters for the decision tree regressor, we will\n",
        "optimize the `max_depth` of the tree. Vary the `max_depth` from 1 level up to 15\n",
        "levels. Use nested cross-validation to evaluate a grid-search\n",
        "(`sklearn.model_selection.GridSearchCV`). Set `cv=10` for both the inner and\n",
        "outer cross-validations, then answer the questions below.\n",
        "\n",
        "## Question 2\n",
        "```\n",
        "What is the optimal tree depth for the current problem?\n",
        "\n",
        "- a) The optimal depth is ranging from 3 to 5\n",
        "- b) The optimal depth is ranging from 5 to 8\n",
        "- c) The optimal depth is ranging from 8 to 11\n",
        "- d) The optimal depth is ranging from 11 to 15\n",
        "\n",
        "_Select a single answer_\n",
        "```\n",
        "\n",
        "Now, we want to evaluate the generalization performance of the decision tree\n",
        "while taking into account the fact that we tune the depth for this specific\n",
        "dataset. Use the grid-search as an estimator inside a `cross_validate` to\n",
        "automatically tune the `max_depth` parameter on each cross-validation\n",
        "fold.\n",
        "\n",
        "## Question 3\n",
        "\n",
        "```\n",
        "A tree with tuned depth\n",
        "\n",
        "- a) is always worse than the linear models on all CV folds\n",
        "- b) is often but not always worse than the linear model\n",
        "- c) is often but not always better than the linear model\n",
        "- d) is always better than the linear models on all CV folds\n",
        "\n",
        "_Select a single answer_\n",
        "\n",
        "Note: Try to set the random_state of the decision tree to different values\n",
        "e.g. random_state=1 or random_state=2 and re-run the nested cross-validation\n",
        "to check that your answer is stable enough.\n",
        "```\n",
        "\n",
        "\n",
        "Instead of using only the numerical features you will now use the entire dataset\n",
        "available in the variable `data`.\n",
        "\n",
        "Create a preprocessor by dealing separately with the numerical and categorical\n",
        "columns. For the sake of simplicity, we will assume the following:\n",
        "\n",
        "- categorical columns can be selected if they have an `object` data type;\n",
        "- use an `OrdinalEncoder` to encode the categorical columns;\n",
        "- numerical columns should correspond to the `numerical_features` as defined above.\n",
        "  This is a subset of the features that are not an `object` data type.\n",
        "\n",
        "In addition, set the `max_depth` of the decision tree to `7` (fixed, no need\n",
        "to tune it with a grid-search).\n",
        "\n",
        "Evaluate this model using `cross_validate` as in the previous questions.\n",
        "\n",
        "## Question 4\n",
        "```\n",
        "A tree model trained with both numerical and categorical features\n",
        "\n",
        "- a) is most often worse than the tree model using only the numerical features\n",
        "- b) is most often better than the tree model using only the numerical features\n",
        "\n",
        "_Select a single answer_\n",
        "\n",
        "Note: Try to set the random_state of the decision tree to different values\n",
        "e.g. random_state=1 or random_state=2 and re-run the (this time single) cross-validation\n",
        "to check that your answer is stable enough.\n",
        "```\n"
      ],
      "metadata": {
        "id": "kF4UZvosZJMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###QUESTION 1\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "\n",
        "linear_model = Pipeline([(\"scaler\", StandardScaler()),(\"regressor\", LinearRegression())])\n",
        "cv_results_linear = cross_validate(linear_model, data_numerical, target, cv=cv, scoring=\"r2\")\n",
        "linear_scores = cv_results_linear['test_score']\n",
        "\n",
        "\n",
        "tree_model_default = DecisionTreeRegressor(random_state=0)\n",
        "cv_results_tree_default = cross_validate(tree_model_default, data_numerical, target, cv=cv, scoring=\"r2\")\n",
        "tree_default_scores = cv_results_tree_default['test_score']\n",
        "\n",
        "\n",
        "print(\"Scores R2 du modèle linéaire \", linear_scores)\n",
        "print(\"Scores R2 de l'arbre par défaut \",tree_default_scores)\n"
      ],
      "metadata": {
        "id": "GSQ3nH_ceHHO",
        "outputId": "bb98e70d-7e54-4f58-edf3-1f9bbf5e4294",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores R2 du modèle linéaire  [0.72416383 0.13509425 0.81251293 0.79197073 0.59758394 0.81767854\n",
            " 0.75115796 0.79453411 0.75305601 0.79411196]\n",
            "Scores R2 de l'arbre par défaut  [0.72687294 0.59050322 0.77618238 0.64072861 0.35374995 0.59738904\n",
            " 0.68771746 0.64235461 0.71297596 0.63349139]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle linéaire a eu un meilleur score 8 fois sur 10.\n",
        "Réponse Q1: c)"
      ],
      "metadata": {
        "id": "iD7v-wQ_CUOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###QUESTION 2\n",
        "\n",
        "param_grid = {'max_depth': range(1, 16)}\n",
        "\n",
        "grid_search = GridSearchCV(DecisionTreeRegressor(random_state=0),param_grid=param_grid,cv=cv,scoring=\"r2\")\n",
        "\n",
        "grid_search.fit(data_numerical, target)\n",
        "optimal_depth = grid_search.best_params_['max_depth']\n",
        "\n",
        "print(\"optimal depth\",optimal_depth)"
      ],
      "metadata": {
        "id": "BCf-4ZKMCvRX",
        "outputId": "2f994c64-91b8-4903-b62d-4fc04e560472",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimal depth 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Profondeur optimale trouvée par GridSearchCV : 5\n",
        "\n",
        "Réponse Q2: a)\n"
      ],
      "metadata": {
        "id": "ZymzXoHGDNSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###QUESTION 3\n"
      ],
      "metadata": {
        "id": "Mdr_SmcJEI34"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}