{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Wrap-up Quiz - Linear Models\n",
        "**This quiz requires some programming to be answered.**\n",
        "\n",
        "Open the dataset `ames_housing_no_missing.csv` with the following command:"
      ],
      "metadata": {
        "id": "ciQzFZ2qNsfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "ames_housing = pd.read_csv(\"https://raw.githubusercontent.com/bilals/scikit-learn-mooc/main/datasets/ames_housing_no_missing.csv\")\n",
        "target_name = \"SalePrice\"\n",
        "data = ames_housing.drop(columns=target_name)\n",
        "target = ames_housing[target_name]"
      ],
      "metadata": {
        "id": "wP3pyiRdKObY"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ames_housing` is a pandas dataframe. The column “SalePrice” contains the target variable.\n",
        "\n",
        "To simplify this exercise, we will only used the numerical features defined below:"
      ],
      "metadata": {
        "id": "Exp20UWMOUV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = [\n",
        "    \"LotFrontage\", \"LotArea\", \"MasVnrArea\", \"BsmtFinSF1\", \"BsmtFinSF2\",\n",
        "    \"BsmtUnfSF\", \"TotalBsmtSF\", \"1stFlrSF\", \"2ndFlrSF\", \"LowQualFinSF\",\n",
        "    \"GrLivArea\", \"BedroomAbvGr\", \"KitchenAbvGr\", \"TotRmsAbvGrd\", \"Fireplaces\",\n",
        "    \"GarageCars\", \"GarageArea\", \"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\",\n",
        "    \"3SsnPorch\", \"ScreenPorch\", \"PoolArea\", \"MiscVal\",\n",
        "]\n",
        "\n",
        "data_numerical = data[numerical_features]"
      ],
      "metadata": {
        "id": "FJKDvwhgzdpw"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start by fitting a ridge regressor (`sklearn.linear_model.Ridge`) fixing the penalty `alpha` to 0 to not regularize the model. Use a 10-fold cross-validation and pass the argument `return_estimator=True` in sklearn.`model_selection.cross_validate` to access all fitted estimators fitted on each fold. Use an instance of `sklearn.preprocessing.StandardScaler` to scale the data before passing it to the regressor."
      ],
      "metadata": {
        "id": "O21TG43KOeq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline= make_pipeline(StandardScaler(), Ridge(alpha=0))\n",
        "cross_validation = cross_validate(pipeline,data_numerical,target,cv=10,return_estimator=True)\n",
        "coefs=pd.DataFrame([pipeline[-1].coef_ for pipeline in cross_validation[\"estimator\"]], columns=numerical_features)\n",
        "\n",
        "\n",
        "max_abs_coef = coefs.abs().max().max()\n",
        "print(max_abs_coef)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSAqKkN5zctL",
        "outputId": "e54133c0-1013-48c2-9f07-d7016411e81c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=3.14082e-17): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=1.48388e-17): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=5.80818e-18): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=3.08256e-17): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.514929864668917e+18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=5.35911e-18): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=1.5769e-17): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=2.35724e-17): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1\n",
        "How large is the largest absolute value of the weight (coefficient) in this trained model?\n",
        "\n",
        "a) Lower than 1.0 (1e0)\n",
        "\n",
        "b) Between 1.0 (1e0) and 100,000.0 (1e5)\n",
        "\n",
        "\n",
        "**c) Larger than 100,000.0 (1e5)**\n",
        "\n",
        "\n",
        "*Select a single answer*\n",
        "\n",
        "Hint: Note that the estimator fitted in each fold of the cross-validation procedure is a pipeline object. To access the coefficients of the `Ridge` model at the last position in a pipeline object, you can use the expression `pipeline[-1].coef_` for each pipeline object fitted in the cross-validation procedure. The `-1` notation is a negative index meaning “last position”."
      ],
      "metadata": {
        "id": "CC-bI9XJOtcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline2= make_pipeline(StandardScaler(), Ridge(alpha=1))\n",
        "cross_validation2 = cross_validate(pipeline2,data_numerical,target,cv=10,return_estimator=True)\n",
        "coefs2=pd.DataFrame([pipeline2[-1].coef_ for pipeline2 in cross_validation2[\"estimator\"]], columns=numerical_features)\n",
        "\n",
        "\n",
        "max_abs_coef2 = coefs2.abs().max().max()\n",
        "print(max_abs_coef2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqbT5hOm3yyT",
        "outputId": "de2ddad1-4296-4778-b294-55a8c86e8510"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22562.769198255974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2\n",
        "\n",
        "Repeat the same experiment by fitting a ridge regressor (`sklearn.linear_model.Ridge`) with the default parameter (i.e. `alpha=1.0`).\n",
        "\n",
        "How large is the largest absolute value of the weight (coefficient) in this trained model?\n",
        "\n",
        "a) Lower than 1.0\n",
        "\n",
        "**b) Between 1.0 and 100,000.0**\n",
        "\n",
        "c) Larger than 100,000.0\n",
        "\n",
        "*Select a single answer*"
      ],
      "metadata": {
        "id": "UKes25qtPeZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_coefs = coefs2.abs().mean().sort_values(ascending=False)\n",
        "print(mean_coefs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scCN5xrk4IPD",
        "outputId": "bbd9ac7a-4776-4b0f-a418-fdc7a9161924"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GarageCars       19417.910189\n",
            "GrLivArea        17119.540942\n",
            "2ndFlrSF         12201.988699\n",
            "TotRmsAbvGrd     12152.055864\n",
            "BedroomAbvGr     12117.822236\n",
            "TotalBsmtSF      11947.838543\n",
            "KitchenAbvGr     10791.538866\n",
            "1stFlrSF          9701.912155\n",
            "BsmtFinSF1        8574.144931\n",
            "MasVnrArea        6862.664154\n",
            "WoodDeckSF        4763.085964\n",
            "Fireplaces        3087.058747\n",
            "BsmtUnfSF         3078.259716\n",
            "EnclosedPorch     2735.318700\n",
            "OpenPorchSF       2095.684415\n",
            "PoolArea          1778.852121\n",
            "LowQualFinSF      1718.353818\n",
            "GarageArea        1714.838363\n",
            "ScreenPorch       1634.099935\n",
            "LotArea           1508.092126\n",
            "3SsnPorch          943.744522\n",
            "LotFrontage        660.816462\n",
            "MiscVal            358.624461\n",
            "BsmtFinSF2         353.776625\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3\n",
        "\n",
        "What are the two most important features used by the ridge regressor? You can make a box-plot of the coefficients across all folds to get a good insight.\n",
        "\n",
        "a) \"`MiscVal`\" and \"`BsmtFinSF1`\"\n",
        "\n",
        "**b) \"`GarageCars`\" and \"`GrLivArea`\"**\n",
        "\n",
        "c) \"`TotalBsmtSF`\" and \"`GarageCars`\"\n",
        "\n",
        "*Select a single answer*"
      ],
      "metadata": {
        "id": "NBku9MO0R_Fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_numerical_no_GarageArea = data_numerical.drop(columns=\"GarageArea\")\n",
        "\n",
        "pipeline4 = make_pipeline(StandardScaler(), Ridge(alpha=1.0))\n",
        "cross_validation4 = cross_validate(pipeline4,data_numerical_no_GarageArea,target,cv=10,return_estimator=True)\n",
        "coefs4=pd.DataFrame([pipeline4[-1].coef_ for pipeline4 in cross_validation4[\"estimator\"]], columns=numerical_features_no_GarageArea)\n",
        "\n",
        "mean_coefs4 = coefs4.abs().mean().sort_values(ascending=False)\n",
        "print(mean_coefs4)\n",
        "std2 = coefs2[\"GarageCars\"].std()\n",
        "std4 = coefs4[\"GarageCars\"].std()\n",
        "print(std2)\n",
        "print(std4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-P9-J2u5Iib",
        "outputId": "95ffb37c-fe3f-45f9-be5b-4c3196393ef6"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GarageCars       18837.624639\n",
            "GrLivArea        17076.030423\n",
            "2ndFlrSF         12193.817284\n",
            "TotRmsAbvGrd     12176.413406\n",
            "BedroomAbvGr     12092.040379\n",
            "TotalBsmtSF      11920.702433\n",
            "KitchenAbvGr     10781.071576\n",
            "1stFlrSF          9652.195672\n",
            "BsmtFinSF1        8537.873135\n",
            "MasVnrArea        6844.983720\n",
            "WoodDeckSF        4758.777609\n",
            "Fireplaces        3134.199017\n",
            "BsmtUnfSF         3088.973049\n",
            "EnclosedPorch     2746.834573\n",
            "OpenPorchSF       2072.478059\n",
            "PoolArea          1790.586368\n",
            "LowQualFinSF      1721.808665\n",
            "ScreenPorch       1629.835272\n",
            "LotArea           1498.967540\n",
            "3SsnPorch          947.049886\n",
            "LotFrontage        718.430805\n",
            "BsmtFinSF2         353.976455\n",
            "MiscVal            352.776308\n",
            "dtype: float64\n",
            "2895.2876461017318\n",
            "1305.1393941886613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4\n",
        "\n",
        "Remove the feature \"`GarageArea`\" from the dataset and repeat the previous experiment.\n",
        "\n",
        "\n",
        "What is the impact on the weights of removing \"`GarageArea`\" from the dataset?\n",
        "\n",
        "a) None\n",
        "\n",
        "b) Completely changes the order of the most important features\n",
        "\n",
        "`c) Decreases the standard deviation (across CV folds) of the \"GarageCars\" coefficient `\n",
        "\n",
        "*Select all answers that apply*"
      ],
      "metadata": {
        "id": "KgZFOAmzSdpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correlation = data[[\"GarageCars\", \"GarageArea\"]].corr()\n",
        "print(correlation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd_b1cp7AcKm",
        "outputId": "026af6e2-63b4-4245-d09a-570e30de7a06"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            GarageCars  GarageArea\n",
            "GarageCars    1.000000    0.882475\n",
            "GarageArea    0.882475    1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5\n",
        "\n",
        "What is the main reason for observing the previous impact on the most important weight(s)?\n",
        "\n",
        "**a) Both garage features are correlated and are carrying similar information**\n",
        "\n",
        "b) Removing the `“GarageArea”` feature reduces the noise in the dataset\n",
        "\n",
        "c) Just some random effects\n",
        "\n",
        "*Select a single answer*\n",
        "\n"
      ],
      "metadata": {
        "id": "TWVpBxcdUnu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import RidgeCV\n",
        "\n",
        "alphas = np.logspace(-3, 3, num=101)\n",
        "pipeline6 = make_pipeline(StandardScaler(), RidgeCV(alphas=alphas))\n",
        "cross_validation6 = cross_validate(pipeline6, data_numerical, target, cv=10, return_estimator=True)\n",
        "\n",
        "coefs6 = [pipeline6[-1].coef_ for pipeline6 in cross_validation6[\"estimator\"]]\n",
        "coefs6 = pd.DataFrame(coefs6, columns=data_numerical.columns)\n",
        "coefs6[\"GarageCars\"].std()"
      ],
      "metadata": {
        "id": "HrReUNNbFouQ",
        "outputId": "4275d351-808d-4603-eb27-d5da1a16400d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "635.558419772785"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6\n",
        "\n",
        "Now, we will search for the regularization strength that maximizes the generalization performance of our predictive model. Fit a `sklearn.linear_model.RidgeCV` instead of a `Ridge` regressor on the numerical data without the \"`GarageArea`\" column. Pass `alphas=np.logspace(-3, 3, num=101)` to explore the effect of changing the regularization strength.\n",
        "\n",
        "What is the effect of tuning alpha on the variability of the weights of the feature \"GarageCars\"? Remember that the variability can be assessed by computing the standard deviation.\n",
        "\n",
        "a) The variability does not change after tuning alpha\n",
        "\n",
        "**b) The variability decreased after tuning alpha**\n",
        "\n",
        "c) The variability increased after tuning alpha\n",
        "\n",
        "*Select a single answer*"
      ],
      "metadata": {
        "id": "FW3IDzZXWCsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = [\n",
        "    \"LotFrontage\", \"LotArea\", \"MasVnrArea\", \"BsmtFinSF1\", \"BsmtFinSF2\",\n",
        "    \"BsmtUnfSF\", \"TotalBsmtSF\", \"1stFlrSF\", \"2ndFlrSF\", \"LowQualFinSF\",\n",
        "    \"GrLivArea\", \"BedroomAbvGr\", \"KitchenAbvGr\", \"TotRmsAbvGrd\", \"Fireplaces\",\n",
        "    \"GarageCars\", \"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\",\n",
        "    \"3SsnPorch\", \"ScreenPorch\", \"PoolArea\", \"MiscVal\",\n",
        "]\n",
        "\n",
        "# removed : \"GarageArea\"\n",
        "\n",
        "data_numerical = data[numerical_features]"
      ],
      "metadata": {
        "id": "55vYEWMK7vZR"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 7\n",
        "\n",
        "Check the parameter `alpha_` (the regularization strength) for the different ridge regressors obtained on each fold.\n",
        "\n",
        "In which range does `alpha_` fall into for most folds?\n",
        "\n",
        "a) between 0.1 and 1\n",
        "\n",
        "b) between 1 and 10\n",
        "\n",
        "c) between 10 and 100\n",
        "\n",
        "d) between 100 and 1000\n",
        "\n",
        "*Select a single answer*"
      ],
      "metadata": {
        "id": "0n2wlbN8WlGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 8\n",
        "\n",
        "Now, we will tackle a classification problem instead of a regression problem. Load the Adult Census dataset with the following snippet of code and we will work only with numerical features."
      ],
      "metadata": {
        "id": "o09pXQ6fXcuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adult_census = pd.read_csv(\"https://raw.githubusercontent.com/bilals/scikit-learn-mooc/main/datasets/adult-census.csv\")\n",
        "target = adult_census[\"class\"]\n",
        "data = adult_census.select_dtypes([\"integer\", \"floating\"])\n",
        "data = data.drop(columns=[\"education-num\"])"
      ],
      "metadata": {
        "id": "fpXmLp1v8us4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many numerical features are present in the dataset contained in the variable `data`?\n",
        "\n",
        "a) 3\n",
        "\n",
        "b) 4\n",
        "\n",
        "c) 5\n",
        "\n",
        "*Select a single answer*"
      ],
      "metadata": {
        "id": "rWw56e63Xvgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 9\n",
        "\n",
        "Compare the generalization performance using the accuracy of the two following predictive models using a 10-fold `cross-validation`:\n",
        "\n",
        "* a linear model composed of a `StandardScaler` and a `LogisticRegression`\n",
        "\n",
        "* a `DummyClassifier` predicting the most frequent class\n",
        "\n",
        "By comparing the `cross-validation` test scores of both models fold-to-fold, count the number of times the linear model has a better test score than the dummy classifier Select the range which this number belongs to:\n",
        "\n",
        "a) [0, 3]: the linear model is substantially worse than the dummy classifier\n",
        "\n",
        "b) [4, 6]: both models are almost equivalent\n",
        "\n",
        "c) [7, 10]: the linear model is substantially better than the dummy classifier\n",
        "\n",
        "*Select a single answer*"
      ],
      "metadata": {
        "id": "LAVa2PsEX9S2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 10\n",
        "\n",
        "What is the most important feature seen by the logistic regression?\n",
        "\n",
        "a) \"`age`\"\n",
        "\n",
        "b) \"`capital-gain`\"\n",
        "\n",
        "c) \"`capital-loss`\"\n",
        "\n",
        "d) \"`hours-per-week`\"\n",
        "\n",
        "*Select a single answer*"
      ],
      "metadata": {
        "id": "HXlVlcubYoVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 11\n",
        "\n",
        "Now, we will work with **both numerical and categorical features**. You can load Adult Census with the following snippet:"
      ],
      "metadata": {
        "id": "3aTqz4cxZOo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adult_census = pd.read_csv(\"https://raw.githubusercontent.com/bilals/scikit-learn-mooc/main/datasets/adult-census.csv\")\n",
        "target = adult_census[\"class\"]\n",
        "data = adult_census.drop(columns=[\"class\", \"education-num\"])"
      ],
      "metadata": {
        "id": "Hi3O3Q2XU7II"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a predictive model where the categorical data must be one-hot encoded, the numerical data must be scaled, and the predictor is a logistic regression classifier.\n",
        "\n",
        "Use the same 10-fold cross-validation strategy as above to evaluate this complex pipeline."
      ],
      "metadata": {
        "id": "TpZmRJCkZhf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at the cross-validation test scores for both models and count the number of times the model using both numerical and categorical features has a better test score than the model using only numerical features. Select the range which this number belongs to:\n",
        "\n",
        "a) [0, 3]: the model using both numerical and categorical features is substantially worse than the model using only numerical features\n",
        "\n",
        "b) [4, 6]: both models are almost equivalent\n",
        "\n",
        "c) [7, 10]: the model using both numerical and categorical features is substantially better than the model using only numerical features\n",
        "\n",
        "*Select a single answer*"
      ],
      "metadata": {
        "id": "LS0r2IlzZkeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 12\n",
        "\n",
        "For the following questions, you can use the following snippet to get the feature names after the preprocessing performed."
      ],
      "metadata": {
        "id": "RHxMNijBbJVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor.fit(data)\n",
        "feature_names = (preprocessor.named_transformers_[\"one-hot-encoder\"].get_feature_names_out(categorical_columns)).tolist()\n",
        "feature_names += numerical_columns\n",
        "feature_names"
      ],
      "metadata": {
        "id": "0te9fBfhZ6cj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "c9474ba5-984a-4c16-975d-899317cccefa"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'preprocessor' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-37569154.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_transformers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"one-hot-encoder\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnumerical_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preprocessor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is as many feature names as coefficients in the last step of your predictive pipeline.\n",
        "\n",
        "Which of the following pair of features is most impacting the predictions of the logistic regression classifier based on the relative magnitude of its coefficients?\n",
        "\n",
        "a) \"`hours-per-week`\" and \"`native-country_Columbia`\"\n",
        "\n",
        "b) \"`workclass_?`\" and \"`native_country_?`\"\n",
        "\n",
        "c) \"`capital-gain`\" and \"`education_Doctorate`\"\n",
        "\n",
        "*Select a single answer*"
      ],
      "metadata": {
        "id": "Wg8cqFOybRt3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 13\n",
        "\n",
        "What is the effect of decreasing the `C` parameter on the coefficients?\n",
        "\n",
        "a) shrinking the magnitude of the weights towards zeros\n",
        "\n",
        "b) increasing the magnitude of the weights\n",
        "\n",
        "c) reducing the weights’ variance\n",
        "\n",
        "d) increasing the weights’ variance\n",
        "\n",
        "e) it has no influence on the weights’ variance\n",
        "\n",
        "*Select all answers that apply*"
      ],
      "metadata": {
        "id": "H9Q6s4yrb1KL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further Readings\n",
        "For more info on the importance of feature scaling when applying regularization on linear models:\n",
        "\n",
        "https://inria.github.io/scikit-learn-mooc/python_scripts/linear_models_regularization.html\n",
        "\n",
        "For a discussion on the effect of changing the `C` parameter:\n",
        "\n",
        "https://inria.github.io/scikit-learn-mooc/python_scripts/linear_models_ex_04.html\n",
        "\n"
      ],
      "metadata": {
        "id": "VpTFHflxcC_C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1nTqL3SaoRvb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}